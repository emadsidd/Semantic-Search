{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 2500,
  "global_step": 33876,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00590388475616956,
      "grad_norm": 2.2703683376312256,
      "learning_rate": 1.9940961152438305e-05,
      "loss": 1.0135,
      "step": 100
    },
    {
      "epoch": 0.01180776951233912,
      "grad_norm": 2.2978994846343994,
      "learning_rate": 1.988192230487661e-05,
      "loss": 0.848,
      "step": 200
    },
    {
      "epoch": 0.017711654268508677,
      "grad_norm": 2.1559183597564697,
      "learning_rate": 1.9822883457314914e-05,
      "loss": 0.8054,
      "step": 300
    },
    {
      "epoch": 0.02361553902467824,
      "grad_norm": 2.0656187534332275,
      "learning_rate": 1.976384460975322e-05,
      "loss": 0.7721,
      "step": 400
    },
    {
      "epoch": 0.0295194237808478,
      "grad_norm": 1.8601759672164917,
      "learning_rate": 1.9704805762191524e-05,
      "loss": 0.7412,
      "step": 500
    },
    {
      "epoch": 0.035423308537017355,
      "grad_norm": 1.9829280376434326,
      "learning_rate": 1.964576691462983e-05,
      "loss": 0.721,
      "step": 600
    },
    {
      "epoch": 0.04132719329318692,
      "grad_norm": 2.1739046573638916,
      "learning_rate": 1.9586728067068133e-05,
      "loss": 0.7299,
      "step": 700
    },
    {
      "epoch": 0.04723107804935648,
      "grad_norm": 1.8385931253433228,
      "learning_rate": 1.9527689219506436e-05,
      "loss": 0.7136,
      "step": 800
    },
    {
      "epoch": 0.053134962805526036,
      "grad_norm": 1.9268070459365845,
      "learning_rate": 1.9468650371944743e-05,
      "loss": 0.7149,
      "step": 900
    },
    {
      "epoch": 0.0590388475616956,
      "grad_norm": 1.9070039987564087,
      "learning_rate": 1.9409611524383046e-05,
      "loss": 0.6975,
      "step": 1000
    },
    {
      "epoch": 0.06494273231786515,
      "grad_norm": 1.9147839546203613,
      "learning_rate": 1.9350572676821352e-05,
      "loss": 0.6977,
      "step": 1100
    },
    {
      "epoch": 0.07084661707403471,
      "grad_norm": 2.106241226196289,
      "learning_rate": 1.9291533829259655e-05,
      "loss": 0.6804,
      "step": 1200
    },
    {
      "epoch": 0.07675050183020428,
      "grad_norm": 1.9752306938171387,
      "learning_rate": 1.9232494981697958e-05,
      "loss": 0.6861,
      "step": 1300
    },
    {
      "epoch": 0.08265438658637383,
      "grad_norm": 1.9397283792495728,
      "learning_rate": 1.9173456134136265e-05,
      "loss": 0.6816,
      "step": 1400
    },
    {
      "epoch": 0.08855827134254339,
      "grad_norm": 1.7446820735931396,
      "learning_rate": 1.9114417286574568e-05,
      "loss": 0.6665,
      "step": 1500
    },
    {
      "epoch": 0.09446215609871296,
      "grad_norm": 1.9266475439071655,
      "learning_rate": 1.9055378439012874e-05,
      "loss": 0.6675,
      "step": 1600
    },
    {
      "epoch": 0.10036604085488252,
      "grad_norm": 1.8974390029907227,
      "learning_rate": 1.8996339591451177e-05,
      "loss": 0.6692,
      "step": 1700
    },
    {
      "epoch": 0.10626992561105207,
      "grad_norm": 1.9192477464675903,
      "learning_rate": 1.8937300743889483e-05,
      "loss": 0.6569,
      "step": 1800
    },
    {
      "epoch": 0.11217381036722163,
      "grad_norm": 2.005664587020874,
      "learning_rate": 1.8878261896327787e-05,
      "loss": 0.6593,
      "step": 1900
    },
    {
      "epoch": 0.1180776951233912,
      "grad_norm": 1.676033854484558,
      "learning_rate": 1.881922304876609e-05,
      "loss": 0.661,
      "step": 2000
    },
    {
      "epoch": 0.12398157987956075,
      "grad_norm": 1.6882691383361816,
      "learning_rate": 1.8760184201204396e-05,
      "loss": 0.6465,
      "step": 2100
    },
    {
      "epoch": 0.1298854646357303,
      "grad_norm": 1.8200172185897827,
      "learning_rate": 1.87011453536427e-05,
      "loss": 0.6437,
      "step": 2200
    },
    {
      "epoch": 0.13578934939189988,
      "grad_norm": 1.7311583757400513,
      "learning_rate": 1.8642106506081002e-05,
      "loss": 0.641,
      "step": 2300
    },
    {
      "epoch": 0.14169323414806942,
      "grad_norm": 1.7621572017669678,
      "learning_rate": 1.858306765851931e-05,
      "loss": 0.6491,
      "step": 2400
    },
    {
      "epoch": 0.147597118904239,
      "grad_norm": 1.7019007205963135,
      "learning_rate": 1.852402881095761e-05,
      "loss": 0.6489,
      "step": 2500
    },
    {
      "epoch": 0.15350100366040856,
      "grad_norm": 1.8728506565093994,
      "learning_rate": 1.8464989963395915e-05,
      "loss": 0.6482,
      "step": 2600
    },
    {
      "epoch": 0.1594048884165781,
      "grad_norm": 1.8417078256607056,
      "learning_rate": 1.840595111583422e-05,
      "loss": 0.6353,
      "step": 2700
    },
    {
      "epoch": 0.16530877317274767,
      "grad_norm": 1.7402468919754028,
      "learning_rate": 1.8346912268272524e-05,
      "loss": 0.6383,
      "step": 2800
    },
    {
      "epoch": 0.17121265792891724,
      "grad_norm": 1.7287288904190063,
      "learning_rate": 1.828787342071083e-05,
      "loss": 0.6414,
      "step": 2900
    },
    {
      "epoch": 0.17711654268508678,
      "grad_norm": 1.831571340560913,
      "learning_rate": 1.8228834573149134e-05,
      "loss": 0.648,
      "step": 3000
    },
    {
      "epoch": 0.18302042744125635,
      "grad_norm": 1.8889299631118774,
      "learning_rate": 1.8169795725587437e-05,
      "loss": 0.63,
      "step": 3100
    },
    {
      "epoch": 0.18892431219742592,
      "grad_norm": 1.8966375589370728,
      "learning_rate": 1.8110756878025743e-05,
      "loss": 0.632,
      "step": 3200
    },
    {
      "epoch": 0.19482819695359546,
      "grad_norm": 1.6686309576034546,
      "learning_rate": 1.8051718030464046e-05,
      "loss": 0.619,
      "step": 3300
    },
    {
      "epoch": 0.20073208170976503,
      "grad_norm": 1.6808030605316162,
      "learning_rate": 1.799267918290235e-05,
      "loss": 0.6259,
      "step": 3400
    },
    {
      "epoch": 0.20663596646593457,
      "grad_norm": 1.7501329183578491,
      "learning_rate": 1.7933640335340655e-05,
      "loss": 0.6197,
      "step": 3500
    },
    {
      "epoch": 0.21253985122210414,
      "grad_norm": 1.710672378540039,
      "learning_rate": 1.787460148777896e-05,
      "loss": 0.6156,
      "step": 3600
    },
    {
      "epoch": 0.2184437359782737,
      "grad_norm": 1.8052781820297241,
      "learning_rate": 1.7815562640217265e-05,
      "loss": 0.6117,
      "step": 3700
    },
    {
      "epoch": 0.22434762073444325,
      "grad_norm": 1.64126718044281,
      "learning_rate": 1.7756523792655568e-05,
      "loss": 0.6142,
      "step": 3800
    },
    {
      "epoch": 0.23025150549061282,
      "grad_norm": 1.847313642501831,
      "learning_rate": 1.769748494509387e-05,
      "loss": 0.6098,
      "step": 3900
    },
    {
      "epoch": 0.2361553902467824,
      "grad_norm": 1.8627392053604126,
      "learning_rate": 1.7638446097532177e-05,
      "loss": 0.6112,
      "step": 4000
    },
    {
      "epoch": 0.24205927500295193,
      "grad_norm": 1.7750399112701416,
      "learning_rate": 1.757940724997048e-05,
      "loss": 0.6112,
      "step": 4100
    },
    {
      "epoch": 0.2479631597591215,
      "grad_norm": 1.629561424255371,
      "learning_rate": 1.7520368402408787e-05,
      "loss": 0.6127,
      "step": 4200
    },
    {
      "epoch": 0.2538670445152911,
      "grad_norm": 1.7854281663894653,
      "learning_rate": 1.746132955484709e-05,
      "loss": 0.6185,
      "step": 4300
    },
    {
      "epoch": 0.2597709292714606,
      "grad_norm": 1.8752795457839966,
      "learning_rate": 1.7402290707285393e-05,
      "loss": 0.6145,
      "step": 4400
    },
    {
      "epoch": 0.26567481402763016,
      "grad_norm": 1.715157389640808,
      "learning_rate": 1.73432518597237e-05,
      "loss": 0.6117,
      "step": 4500
    },
    {
      "epoch": 0.27157869878379975,
      "grad_norm": 1.565615177154541,
      "learning_rate": 1.7284213012162002e-05,
      "loss": 0.6084,
      "step": 4600
    },
    {
      "epoch": 0.2774825835399693,
      "grad_norm": 1.7417868375778198,
      "learning_rate": 1.722517416460031e-05,
      "loss": 0.6128,
      "step": 4700
    },
    {
      "epoch": 0.28338646829613884,
      "grad_norm": 1.8263741731643677,
      "learning_rate": 1.7166135317038612e-05,
      "loss": 0.5969,
      "step": 4800
    },
    {
      "epoch": 0.28929035305230844,
      "grad_norm": 1.7990565299987793,
      "learning_rate": 1.710709646947692e-05,
      "loss": 0.6077,
      "step": 4900
    },
    {
      "epoch": 0.295194237808478,
      "grad_norm": 1.6987978219985962,
      "learning_rate": 1.704805762191522e-05,
      "loss": 0.5996,
      "step": 5000
    },
    {
      "epoch": 0.3010981225646475,
      "grad_norm": 1.6996244192123413,
      "learning_rate": 1.6989018774353524e-05,
      "loss": 0.6,
      "step": 5100
    },
    {
      "epoch": 0.3070020073208171,
      "grad_norm": 1.8239094018936157,
      "learning_rate": 1.692997992679183e-05,
      "loss": 0.6013,
      "step": 5200
    },
    {
      "epoch": 0.31290589207698666,
      "grad_norm": 1.6752691268920898,
      "learning_rate": 1.6870941079230134e-05,
      "loss": 0.5948,
      "step": 5300
    },
    {
      "epoch": 0.3188097768331562,
      "grad_norm": 1.7155052423477173,
      "learning_rate": 1.681190223166844e-05,
      "loss": 0.5933,
      "step": 5400
    },
    {
      "epoch": 0.3247136615893258,
      "grad_norm": 1.6388789415359497,
      "learning_rate": 1.6752863384106743e-05,
      "loss": 0.5943,
      "step": 5500
    },
    {
      "epoch": 0.33061754634549534,
      "grad_norm": 1.9572036266326904,
      "learning_rate": 1.669382453654505e-05,
      "loss": 0.6094,
      "step": 5600
    },
    {
      "epoch": 0.3365214311016649,
      "grad_norm": 1.7585686445236206,
      "learning_rate": 1.6634785688983353e-05,
      "loss": 0.5912,
      "step": 5700
    },
    {
      "epoch": 0.3424253158578345,
      "grad_norm": 1.48198664188385,
      "learning_rate": 1.6575746841421656e-05,
      "loss": 0.5926,
      "step": 5800
    },
    {
      "epoch": 0.348329200614004,
      "grad_norm": 1.9253027439117432,
      "learning_rate": 1.6516707993859962e-05,
      "loss": 0.5851,
      "step": 5900
    },
    {
      "epoch": 0.35423308537017356,
      "grad_norm": 1.8069376945495605,
      "learning_rate": 1.6457669146298265e-05,
      "loss": 0.593,
      "step": 6000
    },
    {
      "epoch": 0.36013697012634316,
      "grad_norm": 1.7218818664550781,
      "learning_rate": 1.6398630298736572e-05,
      "loss": 0.585,
      "step": 6100
    },
    {
      "epoch": 0.3660408548825127,
      "grad_norm": 1.6989918947219849,
      "learning_rate": 1.6339591451174875e-05,
      "loss": 0.5837,
      "step": 6200
    },
    {
      "epoch": 0.37194473963868224,
      "grad_norm": 1.7165477275848389,
      "learning_rate": 1.6280552603613178e-05,
      "loss": 0.5983,
      "step": 6300
    },
    {
      "epoch": 0.37784862439485184,
      "grad_norm": 1.5310014486312866,
      "learning_rate": 1.6221513756051484e-05,
      "loss": 0.5907,
      "step": 6400
    },
    {
      "epoch": 0.3837525091510214,
      "grad_norm": 1.7456507682800293,
      "learning_rate": 1.6162474908489787e-05,
      "loss": 0.5948,
      "step": 6500
    },
    {
      "epoch": 0.3896563939071909,
      "grad_norm": 1.5302627086639404,
      "learning_rate": 1.6103436060928094e-05,
      "loss": 0.5905,
      "step": 6600
    },
    {
      "epoch": 0.39556027866336047,
      "grad_norm": 1.761877179145813,
      "learning_rate": 1.6044397213366397e-05,
      "loss": 0.5955,
      "step": 6700
    },
    {
      "epoch": 0.40146416341953006,
      "grad_norm": 1.6348754167556763,
      "learning_rate": 1.5985358365804703e-05,
      "loss": 0.5876,
      "step": 6800
    },
    {
      "epoch": 0.4073680481756996,
      "grad_norm": 1.6005744934082031,
      "learning_rate": 1.5926319518243006e-05,
      "loss": 0.5884,
      "step": 6900
    },
    {
      "epoch": 0.41327193293186915,
      "grad_norm": 1.7604243755340576,
      "learning_rate": 1.586728067068131e-05,
      "loss": 0.5915,
      "step": 7000
    },
    {
      "epoch": 0.41917581768803874,
      "grad_norm": 1.8126803636550903,
      "learning_rate": 1.5808241823119616e-05,
      "loss": 0.5897,
      "step": 7100
    },
    {
      "epoch": 0.4250797024442083,
      "grad_norm": 1.5320216417312622,
      "learning_rate": 1.574920297555792e-05,
      "loss": 0.5868,
      "step": 7200
    },
    {
      "epoch": 0.4309835872003778,
      "grad_norm": 1.7303410768508911,
      "learning_rate": 1.5690164127996225e-05,
      "loss": 0.58,
      "step": 7300
    },
    {
      "epoch": 0.4368874719565474,
      "grad_norm": 1.7278087139129639,
      "learning_rate": 1.5631125280434528e-05,
      "loss": 0.5798,
      "step": 7400
    },
    {
      "epoch": 0.44279135671271697,
      "grad_norm": 1.8312084674835205,
      "learning_rate": 1.557208643287283e-05,
      "loss": 0.5853,
      "step": 7500
    },
    {
      "epoch": 0.4486952414688865,
      "grad_norm": 1.5863971710205078,
      "learning_rate": 1.5513047585311138e-05,
      "loss": 0.5726,
      "step": 7600
    },
    {
      "epoch": 0.4545991262250561,
      "grad_norm": 1.60885751247406,
      "learning_rate": 1.545400873774944e-05,
      "loss": 0.5704,
      "step": 7700
    },
    {
      "epoch": 0.46050301098122565,
      "grad_norm": 1.6540013551712036,
      "learning_rate": 1.5394969890187744e-05,
      "loss": 0.5864,
      "step": 7800
    },
    {
      "epoch": 0.4664068957373952,
      "grad_norm": 1.6699512004852295,
      "learning_rate": 1.533593104262605e-05,
      "loss": 0.5903,
      "step": 7900
    },
    {
      "epoch": 0.4723107804935648,
      "grad_norm": 1.673646092414856,
      "learning_rate": 1.5276892195064353e-05,
      "loss": 0.5816,
      "step": 8000
    },
    {
      "epoch": 0.4782146652497343,
      "grad_norm": 1.6883538961410522,
      "learning_rate": 1.5217853347502658e-05,
      "loss": 0.5788,
      "step": 8100
    },
    {
      "epoch": 0.48411855000590387,
      "grad_norm": 1.6978716850280762,
      "learning_rate": 1.5158814499940961e-05,
      "loss": 0.5897,
      "step": 8200
    },
    {
      "epoch": 0.49002243476207347,
      "grad_norm": 1.6629477739334106,
      "learning_rate": 1.5099775652379267e-05,
      "loss": 0.5831,
      "step": 8300
    },
    {
      "epoch": 0.495926319518243,
      "grad_norm": 1.7330654859542847,
      "learning_rate": 1.504073680481757e-05,
      "loss": 0.5787,
      "step": 8400
    },
    {
      "epoch": 0.5018302042744126,
      "grad_norm": 1.7700872421264648,
      "learning_rate": 1.4981697957255877e-05,
      "loss": 0.5747,
      "step": 8500
    },
    {
      "epoch": 0.5077340890305821,
      "grad_norm": 1.7202814817428589,
      "learning_rate": 1.492265910969418e-05,
      "loss": 0.5762,
      "step": 8600
    },
    {
      "epoch": 0.5136379737867517,
      "grad_norm": 1.6200047731399536,
      "learning_rate": 1.4863620262132485e-05,
      "loss": 0.5755,
      "step": 8700
    },
    {
      "epoch": 0.5195418585429212,
      "grad_norm": 1.7549084424972534,
      "learning_rate": 1.480458141457079e-05,
      "loss": 0.5692,
      "step": 8800
    },
    {
      "epoch": 0.5254457432990908,
      "grad_norm": 1.7259000539779663,
      "learning_rate": 1.4745542567009093e-05,
      "loss": 0.566,
      "step": 8900
    },
    {
      "epoch": 0.5313496280552603,
      "grad_norm": 1.6846497058868408,
      "learning_rate": 1.4686503719447397e-05,
      "loss": 0.5865,
      "step": 9000
    },
    {
      "epoch": 0.53725351281143,
      "grad_norm": 1.751080870628357,
      "learning_rate": 1.4627464871885702e-05,
      "loss": 0.5702,
      "step": 9100
    },
    {
      "epoch": 0.5431573975675995,
      "grad_norm": 1.5333565473556519,
      "learning_rate": 1.4568426024324007e-05,
      "loss": 0.5588,
      "step": 9200
    },
    {
      "epoch": 0.549061282323769,
      "grad_norm": 1.6335597038269043,
      "learning_rate": 1.4509387176762311e-05,
      "loss": 0.5666,
      "step": 9300
    },
    {
      "epoch": 0.5549651670799386,
      "grad_norm": 1.796989917755127,
      "learning_rate": 1.4450348329200614e-05,
      "loss": 0.5742,
      "step": 9400
    },
    {
      "epoch": 0.5608690518361081,
      "grad_norm": 1.534449577331543,
      "learning_rate": 1.439130948163892e-05,
      "loss": 0.5623,
      "step": 9500
    },
    {
      "epoch": 0.5667729365922777,
      "grad_norm": 1.6256123781204224,
      "learning_rate": 1.4332270634077224e-05,
      "loss": 0.5747,
      "step": 9600
    },
    {
      "epoch": 0.5726768213484473,
      "grad_norm": 1.5909111499786377,
      "learning_rate": 1.4273231786515529e-05,
      "loss": 0.5791,
      "step": 9700
    },
    {
      "epoch": 0.5785807061046169,
      "grad_norm": 1.6686352491378784,
      "learning_rate": 1.4214192938953832e-05,
      "loss": 0.5631,
      "step": 9800
    },
    {
      "epoch": 0.5844845908607864,
      "grad_norm": 1.5481401681900024,
      "learning_rate": 1.4155154091392138e-05,
      "loss": 0.5659,
      "step": 9900
    },
    {
      "epoch": 0.590388475616956,
      "grad_norm": 1.6887234449386597,
      "learning_rate": 1.4096115243830441e-05,
      "loss": 0.571,
      "step": 10000
    },
    {
      "epoch": 0.5962923603731255,
      "grad_norm": 1.5842292308807373,
      "learning_rate": 1.4037076396268744e-05,
      "loss": 0.5672,
      "step": 10100
    },
    {
      "epoch": 0.602196245129295,
      "grad_norm": 1.5550730228424072,
      "learning_rate": 1.397803754870705e-05,
      "loss": 0.563,
      "step": 10200
    },
    {
      "epoch": 0.6081001298854647,
      "grad_norm": 1.6232081651687622,
      "learning_rate": 1.3918998701145354e-05,
      "loss": 0.5674,
      "step": 10300
    },
    {
      "epoch": 0.6140040146416342,
      "grad_norm": 1.6789116859436035,
      "learning_rate": 1.385995985358366e-05,
      "loss": 0.5674,
      "step": 10400
    },
    {
      "epoch": 0.6199078993978038,
      "grad_norm": 1.5740605592727661,
      "learning_rate": 1.3800921006021963e-05,
      "loss": 0.5558,
      "step": 10500
    },
    {
      "epoch": 0.6258117841539733,
      "grad_norm": 1.7943121194839478,
      "learning_rate": 1.374188215846027e-05,
      "loss": 0.572,
      "step": 10600
    },
    {
      "epoch": 0.6317156689101429,
      "grad_norm": 1.593738079071045,
      "learning_rate": 1.3682843310898573e-05,
      "loss": 0.573,
      "step": 10700
    },
    {
      "epoch": 0.6376195536663124,
      "grad_norm": 1.8097163438796997,
      "learning_rate": 1.3623804463336876e-05,
      "loss": 0.5716,
      "step": 10800
    },
    {
      "epoch": 0.6435234384224819,
      "grad_norm": 1.6427725553512573,
      "learning_rate": 1.3564765615775182e-05,
      "loss": 0.5677,
      "step": 10900
    },
    {
      "epoch": 0.6494273231786516,
      "grad_norm": 1.686397910118103,
      "learning_rate": 1.3505726768213485e-05,
      "loss": 0.5625,
      "step": 11000
    },
    {
      "epoch": 0.6553312079348211,
      "grad_norm": 1.6961414813995361,
      "learning_rate": 1.3446687920651792e-05,
      "loss": 0.5599,
      "step": 11100
    },
    {
      "epoch": 0.6612350926909907,
      "grad_norm": 1.7290103435516357,
      "learning_rate": 1.3387649073090095e-05,
      "loss": 0.563,
      "step": 11200
    },
    {
      "epoch": 0.6671389774471602,
      "grad_norm": 1.591812014579773,
      "learning_rate": 1.3328610225528398e-05,
      "loss": 0.5652,
      "step": 11300
    },
    {
      "epoch": 0.6730428622033298,
      "grad_norm": 1.5740323066711426,
      "learning_rate": 1.3269571377966704e-05,
      "loss": 0.5645,
      "step": 11400
    },
    {
      "epoch": 0.6789467469594993,
      "grad_norm": 1.605259895324707,
      "learning_rate": 1.3210532530405007e-05,
      "loss": 0.5582,
      "step": 11500
    },
    {
      "epoch": 0.684850631715669,
      "grad_norm": 1.6608587503433228,
      "learning_rate": 1.3151493682843312e-05,
      "loss": 0.5592,
      "step": 11600
    },
    {
      "epoch": 0.6907545164718385,
      "grad_norm": 1.7360401153564453,
      "learning_rate": 1.3092454835281617e-05,
      "loss": 0.5618,
      "step": 11700
    },
    {
      "epoch": 0.696658401228008,
      "grad_norm": 1.7225282192230225,
      "learning_rate": 1.3033415987719921e-05,
      "loss": 0.5624,
      "step": 11800
    },
    {
      "epoch": 0.7025622859841776,
      "grad_norm": 1.7198083400726318,
      "learning_rate": 1.2974377140158226e-05,
      "loss": 0.557,
      "step": 11900
    },
    {
      "epoch": 0.7084661707403471,
      "grad_norm": 1.5633307695388794,
      "learning_rate": 1.2915338292596529e-05,
      "loss": 0.5514,
      "step": 12000
    },
    {
      "epoch": 0.7143700554965167,
      "grad_norm": 1.6201597452163696,
      "learning_rate": 1.2856299445034834e-05,
      "loss": 0.5572,
      "step": 12100
    },
    {
      "epoch": 0.7202739402526863,
      "grad_norm": 1.7301305532455444,
      "learning_rate": 1.2797260597473139e-05,
      "loss": 0.5576,
      "step": 12200
    },
    {
      "epoch": 0.7261778250088559,
      "grad_norm": 1.6536067724227905,
      "learning_rate": 1.2738221749911443e-05,
      "loss": 0.5603,
      "step": 12300
    },
    {
      "epoch": 0.7320817097650254,
      "grad_norm": 1.6241395473480225,
      "learning_rate": 1.2679182902349746e-05,
      "loss": 0.5572,
      "step": 12400
    },
    {
      "epoch": 0.7379855945211949,
      "grad_norm": 1.5681949853897095,
      "learning_rate": 1.2620144054788051e-05,
      "loss": 0.5524,
      "step": 12500
    },
    {
      "epoch": 0.7438894792773645,
      "grad_norm": 1.5882182121276855,
      "learning_rate": 1.2561105207226356e-05,
      "loss": 0.557,
      "step": 12600
    },
    {
      "epoch": 0.749793364033534,
      "grad_norm": 1.6890126466751099,
      "learning_rate": 1.2502066359664659e-05,
      "loss": 0.5516,
      "step": 12700
    },
    {
      "epoch": 0.7556972487897037,
      "grad_norm": 1.6375534534454346,
      "learning_rate": 1.2443027512102965e-05,
      "loss": 0.5535,
      "step": 12800
    },
    {
      "epoch": 0.7616011335458732,
      "grad_norm": 1.5958622694015503,
      "learning_rate": 1.2383988664541268e-05,
      "loss": 0.5572,
      "step": 12900
    },
    {
      "epoch": 0.7675050183020428,
      "grad_norm": 1.5890820026397705,
      "learning_rate": 1.2324949816979575e-05,
      "loss": 0.5549,
      "step": 13000
    },
    {
      "epoch": 0.7734089030582123,
      "grad_norm": 1.7194563150405884,
      "learning_rate": 1.2265910969417878e-05,
      "loss": 0.5571,
      "step": 13100
    },
    {
      "epoch": 0.7793127878143818,
      "grad_norm": 1.5483307838439941,
      "learning_rate": 1.2206872121856181e-05,
      "loss": 0.5569,
      "step": 13200
    },
    {
      "epoch": 0.7852166725705514,
      "grad_norm": 1.838404893875122,
      "learning_rate": 1.2147833274294487e-05,
      "loss": 0.5542,
      "step": 13300
    },
    {
      "epoch": 0.7911205573267209,
      "grad_norm": 1.6331373453140259,
      "learning_rate": 1.208879442673279e-05,
      "loss": 0.5568,
      "step": 13400
    },
    {
      "epoch": 0.7970244420828906,
      "grad_norm": 1.5869140625,
      "learning_rate": 1.2029755579171097e-05,
      "loss": 0.5523,
      "step": 13500
    },
    {
      "epoch": 0.8029283268390601,
      "grad_norm": 1.5882805585861206,
      "learning_rate": 1.19707167316094e-05,
      "loss": 0.5562,
      "step": 13600
    },
    {
      "epoch": 0.8088322115952297,
      "grad_norm": 1.8138152360916138,
      "learning_rate": 1.1911677884047706e-05,
      "loss": 0.5586,
      "step": 13700
    },
    {
      "epoch": 0.8147360963513992,
      "grad_norm": 1.7068188190460205,
      "learning_rate": 1.185263903648601e-05,
      "loss": 0.5535,
      "step": 13800
    },
    {
      "epoch": 0.8206399811075688,
      "grad_norm": 1.6804049015045166,
      "learning_rate": 1.1793600188924312e-05,
      "loss": 0.5551,
      "step": 13900
    },
    {
      "epoch": 0.8265438658637383,
      "grad_norm": 1.5740963220596313,
      "learning_rate": 1.1734561341362619e-05,
      "loss": 0.5537,
      "step": 14000
    },
    {
      "epoch": 0.832447750619908,
      "grad_norm": 1.6242916584014893,
      "learning_rate": 1.1675522493800922e-05,
      "loss": 0.5522,
      "step": 14100
    },
    {
      "epoch": 0.8383516353760775,
      "grad_norm": 1.550201177597046,
      "learning_rate": 1.1616483646239227e-05,
      "loss": 0.5518,
      "step": 14200
    },
    {
      "epoch": 0.844255520132247,
      "grad_norm": 1.6635583639144897,
      "learning_rate": 1.1557444798677531e-05,
      "loss": 0.5542,
      "step": 14300
    },
    {
      "epoch": 0.8501594048884166,
      "grad_norm": 1.6425447463989258,
      "learning_rate": 1.1498405951115834e-05,
      "loss": 0.5595,
      "step": 14400
    },
    {
      "epoch": 0.8560632896445861,
      "grad_norm": 1.701920509338379,
      "learning_rate": 1.1439367103554139e-05,
      "loss": 0.5491,
      "step": 14500
    },
    {
      "epoch": 0.8619671744007557,
      "grad_norm": 1.7394874095916748,
      "learning_rate": 1.1380328255992444e-05,
      "loss": 0.5493,
      "step": 14600
    },
    {
      "epoch": 0.8678710591569253,
      "grad_norm": 1.8149245977401733,
      "learning_rate": 1.1321289408430748e-05,
      "loss": 0.5506,
      "step": 14700
    },
    {
      "epoch": 0.8737749439130948,
      "grad_norm": 1.537376880645752,
      "learning_rate": 1.1262250560869053e-05,
      "loss": 0.5547,
      "step": 14800
    },
    {
      "epoch": 0.8796788286692644,
      "grad_norm": 1.5586776733398438,
      "learning_rate": 1.1203211713307358e-05,
      "loss": 0.5522,
      "step": 14900
    },
    {
      "epoch": 0.8855827134254339,
      "grad_norm": 1.4904831647872925,
      "learning_rate": 1.1144172865745661e-05,
      "loss": 0.5451,
      "step": 15000
    },
    {
      "epoch": 0.8914865981816035,
      "grad_norm": 1.6140921115875244,
      "learning_rate": 1.1085134018183966e-05,
      "loss": 0.5616,
      "step": 15100
    },
    {
      "epoch": 0.897390482937773,
      "grad_norm": 1.5612837076187134,
      "learning_rate": 1.102609517062227e-05,
      "loss": 0.549,
      "step": 15200
    },
    {
      "epoch": 0.9032943676939427,
      "grad_norm": 1.748858094215393,
      "learning_rate": 1.0967056323060574e-05,
      "loss": 0.54,
      "step": 15300
    },
    {
      "epoch": 0.9091982524501122,
      "grad_norm": 1.5967894792556763,
      "learning_rate": 1.090801747549888e-05,
      "loss": 0.5386,
      "step": 15400
    },
    {
      "epoch": 0.9151021372062818,
      "grad_norm": 1.5731791257858276,
      "learning_rate": 1.0848978627937183e-05,
      "loss": 0.5457,
      "step": 15500
    },
    {
      "epoch": 0.9210060219624513,
      "grad_norm": 1.4158554077148438,
      "learning_rate": 1.078993978037549e-05,
      "loss": 0.5537,
      "step": 15600
    },
    {
      "epoch": 0.9269099067186208,
      "grad_norm": 1.6128815412521362,
      "learning_rate": 1.0730900932813792e-05,
      "loss": 0.5503,
      "step": 15700
    },
    {
      "epoch": 0.9328137914747904,
      "grad_norm": 1.4253615140914917,
      "learning_rate": 1.0671862085252095e-05,
      "loss": 0.5517,
      "step": 15800
    },
    {
      "epoch": 0.9387176762309599,
      "grad_norm": 1.543830394744873,
      "learning_rate": 1.0612823237690402e-05,
      "loss": 0.5492,
      "step": 15900
    },
    {
      "epoch": 0.9446215609871296,
      "grad_norm": 1.572369933128357,
      "learning_rate": 1.0553784390128705e-05,
      "loss": 0.5453,
      "step": 16000
    },
    {
      "epoch": 0.9505254457432991,
      "grad_norm": 1.649612307548523,
      "learning_rate": 1.0494745542567011e-05,
      "loss": 0.553,
      "step": 16100
    },
    {
      "epoch": 0.9564293304994687,
      "grad_norm": 1.5641855001449585,
      "learning_rate": 1.0435706695005314e-05,
      "loss": 0.5361,
      "step": 16200
    },
    {
      "epoch": 0.9623332152556382,
      "grad_norm": 1.66362726688385,
      "learning_rate": 1.0376667847443617e-05,
      "loss": 0.5416,
      "step": 16300
    },
    {
      "epoch": 0.9682371000118077,
      "grad_norm": 1.5910106897354126,
      "learning_rate": 1.0317628999881924e-05,
      "loss": 0.5406,
      "step": 16400
    },
    {
      "epoch": 0.9741409847679773,
      "grad_norm": 1.573940396308899,
      "learning_rate": 1.0258590152320227e-05,
      "loss": 0.5359,
      "step": 16500
    },
    {
      "epoch": 0.9800448695241469,
      "grad_norm": 1.7183067798614502,
      "learning_rate": 1.0199551304758533e-05,
      "loss": 0.551,
      "step": 16600
    },
    {
      "epoch": 0.9859487542803165,
      "grad_norm": 1.6851779222488403,
      "learning_rate": 1.0140512457196836e-05,
      "loss": 0.5416,
      "step": 16700
    },
    {
      "epoch": 0.991852639036486,
      "grad_norm": 1.6281944513320923,
      "learning_rate": 1.0081473609635141e-05,
      "loss": 0.5487,
      "step": 16800
    },
    {
      "epoch": 0.9977565237926556,
      "grad_norm": 1.6065926551818848,
      "learning_rate": 1.0022434762073446e-05,
      "loss": 0.5439,
      "step": 16900
    },
    {
      "epoch": 1.0036604085488252,
      "grad_norm": 1.5476144552230835,
      "learning_rate": 9.96339591451175e-06,
      "loss": 0.5352,
      "step": 17000
    },
    {
      "epoch": 1.0095642933049946,
      "grad_norm": 1.6491663455963135,
      "learning_rate": 9.904357066950054e-06,
      "loss": 0.5387,
      "step": 17100
    },
    {
      "epoch": 1.0154681780611643,
      "grad_norm": 1.5577231645584106,
      "learning_rate": 9.845318219388358e-06,
      "loss": 0.5434,
      "step": 17200
    },
    {
      "epoch": 1.0213720628173337,
      "grad_norm": 1.6316019296646118,
      "learning_rate": 9.786279371826663e-06,
      "loss": 0.5455,
      "step": 17300
    },
    {
      "epoch": 1.0272759475735034,
      "grad_norm": 1.4389536380767822,
      "learning_rate": 9.727240524264968e-06,
      "loss": 0.537,
      "step": 17400
    },
    {
      "epoch": 1.033179832329673,
      "grad_norm": 1.6803181171417236,
      "learning_rate": 9.668201676703271e-06,
      "loss": 0.5294,
      "step": 17500
    },
    {
      "epoch": 1.0390837170858425,
      "grad_norm": 1.5437484979629517,
      "learning_rate": 9.609162829141576e-06,
      "loss": 0.5289,
      "step": 17600
    },
    {
      "epoch": 1.0449876018420121,
      "grad_norm": 1.6590640544891357,
      "learning_rate": 9.55012398157988e-06,
      "loss": 0.5396,
      "step": 17700
    },
    {
      "epoch": 1.0508914865981815,
      "grad_norm": 1.5471093654632568,
      "learning_rate": 9.491085134018183e-06,
      "loss": 0.5393,
      "step": 17800
    },
    {
      "epoch": 1.0567953713543512,
      "grad_norm": 1.3837769031524658,
      "learning_rate": 9.432046286456488e-06,
      "loss": 0.5428,
      "step": 17900
    },
    {
      "epoch": 1.0626992561105206,
      "grad_norm": 1.4754360914230347,
      "learning_rate": 9.373007438894793e-06,
      "loss": 0.5369,
      "step": 18000
    },
    {
      "epoch": 1.0686031408666903,
      "grad_norm": 1.50359308719635,
      "learning_rate": 9.313968591333098e-06,
      "loss": 0.5347,
      "step": 18100
    },
    {
      "epoch": 1.07450702562286,
      "grad_norm": 1.6178661584854126,
      "learning_rate": 9.254929743771402e-06,
      "loss": 0.5346,
      "step": 18200
    },
    {
      "epoch": 1.0804109103790294,
      "grad_norm": 1.5916229486465454,
      "learning_rate": 9.195890896209707e-06,
      "loss": 0.5377,
      "step": 18300
    },
    {
      "epoch": 1.086314795135199,
      "grad_norm": 1.5404036045074463,
      "learning_rate": 9.136852048648012e-06,
      "loss": 0.538,
      "step": 18400
    },
    {
      "epoch": 1.0922186798913684,
      "grad_norm": 1.4985053539276123,
      "learning_rate": 9.077813201086315e-06,
      "loss": 0.5364,
      "step": 18500
    },
    {
      "epoch": 1.098122564647538,
      "grad_norm": 1.6961590051651,
      "learning_rate": 9.01877435352462e-06,
      "loss": 0.5378,
      "step": 18600
    },
    {
      "epoch": 1.1040264494037078,
      "grad_norm": 1.5263057947158813,
      "learning_rate": 8.959735505962924e-06,
      "loss": 0.5362,
      "step": 18700
    },
    {
      "epoch": 1.1099303341598772,
      "grad_norm": 1.6847751140594482,
      "learning_rate": 8.900696658401229e-06,
      "loss": 0.5239,
      "step": 18800
    },
    {
      "epoch": 1.1158342189160468,
      "grad_norm": 1.7592389583587646,
      "learning_rate": 8.841657810839534e-06,
      "loss": 0.5459,
      "step": 18900
    },
    {
      "epoch": 1.1217381036722163,
      "grad_norm": 1.6161561012268066,
      "learning_rate": 8.782618963277839e-06,
      "loss": 0.5337,
      "step": 19000
    },
    {
      "epoch": 1.127641988428386,
      "grad_norm": 1.8358032703399658,
      "learning_rate": 8.723580115716142e-06,
      "loss": 0.5266,
      "step": 19100
    },
    {
      "epoch": 1.1335458731845554,
      "grad_norm": 1.7182897329330444,
      "learning_rate": 8.664541268154446e-06,
      "loss": 0.5268,
      "step": 19200
    },
    {
      "epoch": 1.139449757940725,
      "grad_norm": 1.5259586572647095,
      "learning_rate": 8.605502420592751e-06,
      "loss": 0.5394,
      "step": 19300
    },
    {
      "epoch": 1.1453536426968944,
      "grad_norm": 1.6385700702667236,
      "learning_rate": 8.546463573031056e-06,
      "loss": 0.5319,
      "step": 19400
    },
    {
      "epoch": 1.151257527453064,
      "grad_norm": 1.5242481231689453,
      "learning_rate": 8.48742472546936e-06,
      "loss": 0.5471,
      "step": 19500
    },
    {
      "epoch": 1.1571614122092337,
      "grad_norm": 1.5996911525726318,
      "learning_rate": 8.428385877907665e-06,
      "loss": 0.5312,
      "step": 19600
    },
    {
      "epoch": 1.1630652969654032,
      "grad_norm": 1.6386536359786987,
      "learning_rate": 8.369347030345968e-06,
      "loss": 0.5326,
      "step": 19700
    },
    {
      "epoch": 1.1689691817215728,
      "grad_norm": 1.561191439628601,
      "learning_rate": 8.310308182784273e-06,
      "loss": 0.5352,
      "step": 19800
    },
    {
      "epoch": 1.1748730664777423,
      "grad_norm": 1.562463641166687,
      "learning_rate": 8.251269335222578e-06,
      "loss": 0.5428,
      "step": 19900
    },
    {
      "epoch": 1.180776951233912,
      "grad_norm": 1.5983316898345947,
      "learning_rate": 8.19223048766088e-06,
      "loss": 0.5379,
      "step": 20000
    },
    {
      "epoch": 1.1866808359900816,
      "grad_norm": 1.6957662105560303,
      "learning_rate": 8.133191640099186e-06,
      "loss": 0.5317,
      "step": 20100
    },
    {
      "epoch": 1.192584720746251,
      "grad_norm": 1.729400873184204,
      "learning_rate": 8.07415279253749e-06,
      "loss": 0.5323,
      "step": 20200
    },
    {
      "epoch": 1.1984886055024206,
      "grad_norm": 1.6092772483825684,
      "learning_rate": 8.015113944975795e-06,
      "loss": 0.532,
      "step": 20300
    },
    {
      "epoch": 1.20439249025859,
      "grad_norm": 1.610126256942749,
      "learning_rate": 7.956075097414098e-06,
      "loss": 0.5184,
      "step": 20400
    },
    {
      "epoch": 1.2102963750147597,
      "grad_norm": 1.5837557315826416,
      "learning_rate": 7.897036249852403e-06,
      "loss": 0.5319,
      "step": 20500
    },
    {
      "epoch": 1.2162002597709294,
      "grad_norm": 1.4938820600509644,
      "learning_rate": 7.837997402290707e-06,
      "loss": 0.5214,
      "step": 20600
    },
    {
      "epoch": 1.2221041445270988,
      "grad_norm": 1.5930265188217163,
      "learning_rate": 7.778958554729012e-06,
      "loss": 0.5277,
      "step": 20700
    },
    {
      "epoch": 1.2280080292832685,
      "grad_norm": 1.5717276334762573,
      "learning_rate": 7.719919707167317e-06,
      "loss": 0.5206,
      "step": 20800
    },
    {
      "epoch": 1.233911914039438,
      "grad_norm": 1.6129390001296997,
      "learning_rate": 7.660880859605622e-06,
      "loss": 0.5294,
      "step": 20900
    },
    {
      "epoch": 1.2398157987956075,
      "grad_norm": 1.6336750984191895,
      "learning_rate": 7.601842012043925e-06,
      "loss": 0.5283,
      "step": 21000
    },
    {
      "epoch": 1.245719683551777,
      "grad_norm": 1.6988343000411987,
      "learning_rate": 7.5428031644822295e-06,
      "loss": 0.5274,
      "step": 21100
    },
    {
      "epoch": 1.2516235683079466,
      "grad_norm": 1.5926729440689087,
      "learning_rate": 7.483764316920534e-06,
      "loss": 0.5324,
      "step": 21200
    },
    {
      "epoch": 1.257527453064116,
      "grad_norm": 1.7694616317749023,
      "learning_rate": 7.424725469358839e-06,
      "loss": 0.5358,
      "step": 21300
    },
    {
      "epoch": 1.2634313378202857,
      "grad_norm": 1.7184339761734009,
      "learning_rate": 7.365686621797144e-06,
      "loss": 0.5326,
      "step": 21400
    },
    {
      "epoch": 1.2693352225764554,
      "grad_norm": 1.5796592235565186,
      "learning_rate": 7.306647774235448e-06,
      "loss": 0.5295,
      "step": 21500
    },
    {
      "epoch": 1.2752391073326248,
      "grad_norm": 1.6219429969787598,
      "learning_rate": 7.2476089266737514e-06,
      "loss": 0.536,
      "step": 21600
    },
    {
      "epoch": 1.2811429920887945,
      "grad_norm": 1.562069058418274,
      "learning_rate": 7.188570079112056e-06,
      "loss": 0.52,
      "step": 21700
    },
    {
      "epoch": 1.2870468768449639,
      "grad_norm": 1.4652587175369263,
      "learning_rate": 7.129531231550361e-06,
      "loss": 0.534,
      "step": 21800
    },
    {
      "epoch": 1.2929507616011335,
      "grad_norm": 1.6903785467147827,
      "learning_rate": 7.070492383988665e-06,
      "loss": 0.523,
      "step": 21900
    },
    {
      "epoch": 1.2988546463573032,
      "grad_norm": 1.5651534795761108,
      "learning_rate": 7.0114535364269695e-06,
      "loss": 0.5345,
      "step": 22000
    },
    {
      "epoch": 1.3047585311134726,
      "grad_norm": 1.667353868484497,
      "learning_rate": 6.952414688865274e-06,
      "loss": 0.5197,
      "step": 22100
    },
    {
      "epoch": 1.3106624158696423,
      "grad_norm": 1.6438517570495605,
      "learning_rate": 6.893375841303578e-06,
      "loss": 0.5307,
      "step": 22200
    },
    {
      "epoch": 1.3165663006258117,
      "grad_norm": 1.5086109638214111,
      "learning_rate": 6.834336993741882e-06,
      "loss": 0.5192,
      "step": 22300
    },
    {
      "epoch": 1.3224701853819814,
      "grad_norm": 1.419894814491272,
      "learning_rate": 6.775298146180187e-06,
      "loss": 0.5212,
      "step": 22400
    },
    {
      "epoch": 1.328374070138151,
      "grad_norm": 1.553202748298645,
      "learning_rate": 6.7162592986184915e-06,
      "loss": 0.5341,
      "step": 22500
    },
    {
      "epoch": 1.3342779548943204,
      "grad_norm": 1.4710419178009033,
      "learning_rate": 6.657220451056796e-06,
      "loss": 0.5288,
      "step": 22600
    },
    {
      "epoch": 1.34018183965049,
      "grad_norm": 1.624202847480774,
      "learning_rate": 6.598181603495101e-06,
      "loss": 0.5295,
      "step": 22700
    },
    {
      "epoch": 1.3460857244066595,
      "grad_norm": 1.564936876296997,
      "learning_rate": 6.539142755933404e-06,
      "loss": 0.5159,
      "step": 22800
    },
    {
      "epoch": 1.3519896091628292,
      "grad_norm": 1.542926549911499,
      "learning_rate": 6.480103908371709e-06,
      "loss": 0.5266,
      "step": 22900
    },
    {
      "epoch": 1.3578934939189988,
      "grad_norm": 1.461223840713501,
      "learning_rate": 6.4210650608100135e-06,
      "loss": 0.5138,
      "step": 23000
    },
    {
      "epoch": 1.3637973786751683,
      "grad_norm": 1.7882189750671387,
      "learning_rate": 6.362026213248318e-06,
      "loss": 0.5278,
      "step": 23100
    },
    {
      "epoch": 1.3697012634313377,
      "grad_norm": 1.6363416910171509,
      "learning_rate": 6.302987365686622e-06,
      "loss": 0.5262,
      "step": 23200
    },
    {
      "epoch": 1.3756051481875073,
      "grad_norm": 1.4933454990386963,
      "learning_rate": 6.243948518124927e-06,
      "loss": 0.5332,
      "step": 23300
    },
    {
      "epoch": 1.381509032943677,
      "grad_norm": 1.6582777500152588,
      "learning_rate": 6.184909670563232e-06,
      "loss": 0.5263,
      "step": 23400
    },
    {
      "epoch": 1.3874129176998464,
      "grad_norm": 1.6501787900924683,
      "learning_rate": 6.1258708230015355e-06,
      "loss": 0.5329,
      "step": 23500
    },
    {
      "epoch": 1.393316802456016,
      "grad_norm": 1.6145167350769043,
      "learning_rate": 6.066831975439839e-06,
      "loss": 0.5253,
      "step": 23600
    },
    {
      "epoch": 1.3992206872121855,
      "grad_norm": 1.5834928750991821,
      "learning_rate": 6.007793127878144e-06,
      "loss": 0.5353,
      "step": 23700
    },
    {
      "epoch": 1.4051245719683552,
      "grad_norm": 1.5532158613204956,
      "learning_rate": 5.948754280316449e-06,
      "loss": 0.5185,
      "step": 23800
    },
    {
      "epoch": 1.4110284567245248,
      "grad_norm": 1.562626838684082,
      "learning_rate": 5.8897154327547536e-06,
      "loss": 0.5286,
      "step": 23900
    },
    {
      "epoch": 1.4169323414806942,
      "grad_norm": 1.6821768283843994,
      "learning_rate": 5.830676585193058e-06,
      "loss": 0.5293,
      "step": 24000
    },
    {
      "epoch": 1.422836226236864,
      "grad_norm": 1.5958894491195679,
      "learning_rate": 5.771637737631361e-06,
      "loss": 0.5302,
      "step": 24100
    },
    {
      "epoch": 1.4287401109930333,
      "grad_norm": 1.3806272745132446,
      "learning_rate": 5.712598890069666e-06,
      "loss": 0.5245,
      "step": 24200
    },
    {
      "epoch": 1.434643995749203,
      "grad_norm": 1.4720451831817627,
      "learning_rate": 5.653560042507971e-06,
      "loss": 0.5206,
      "step": 24300
    },
    {
      "epoch": 1.4405478805053726,
      "grad_norm": 1.4515503644943237,
      "learning_rate": 5.5945211949462755e-06,
      "loss": 0.5295,
      "step": 24400
    },
    {
      "epoch": 1.446451765261542,
      "grad_norm": 1.5515968799591064,
      "learning_rate": 5.5354823473845794e-06,
      "loss": 0.5174,
      "step": 24500
    },
    {
      "epoch": 1.4523556500177117,
      "grad_norm": 1.5566074848175049,
      "learning_rate": 5.476443499822884e-06,
      "loss": 0.5238,
      "step": 24600
    },
    {
      "epoch": 1.4582595347738811,
      "grad_norm": 1.6312997341156006,
      "learning_rate": 5.417404652261188e-06,
      "loss": 0.5278,
      "step": 24700
    },
    {
      "epoch": 1.4641634195300508,
      "grad_norm": 1.6993086338043213,
      "learning_rate": 5.358365804699493e-06,
      "loss": 0.5283,
      "step": 24800
    },
    {
      "epoch": 1.4700673042862205,
      "grad_norm": 1.7391053438186646,
      "learning_rate": 5.299326957137797e-06,
      "loss": 0.5316,
      "step": 24900
    },
    {
      "epoch": 1.4759711890423899,
      "grad_norm": 1.6055740118026733,
      "learning_rate": 5.240288109576101e-06,
      "loss": 0.5309,
      "step": 25000
    },
    {
      "epoch": 1.4818750737985593,
      "grad_norm": 1.499402403831482,
      "learning_rate": 5.181249262014406e-06,
      "loss": 0.5225,
      "step": 25100
    },
    {
      "epoch": 1.487778958554729,
      "grad_norm": 1.5519317388534546,
      "learning_rate": 5.122210414452711e-06,
      "loss": 0.5325,
      "step": 25200
    },
    {
      "epoch": 1.4936828433108986,
      "grad_norm": 1.5952261686325073,
      "learning_rate": 5.063171566891014e-06,
      "loss": 0.5275,
      "step": 25300
    },
    {
      "epoch": 1.499586728067068,
      "grad_norm": 1.6310317516326904,
      "learning_rate": 5.004132719329319e-06,
      "loss": 0.5254,
      "step": 25400
    },
    {
      "epoch": 1.5054906128232377,
      "grad_norm": 1.6190578937530518,
      "learning_rate": 4.945093871767623e-06,
      "loss": 0.5206,
      "step": 25500
    },
    {
      "epoch": 1.5113944975794071,
      "grad_norm": 1.5926451683044434,
      "learning_rate": 4.886055024205928e-06,
      "loss": 0.5268,
      "step": 25600
    },
    {
      "epoch": 1.5172983823355768,
      "grad_norm": 1.550492525100708,
      "learning_rate": 4.827016176644233e-06,
      "loss": 0.5203,
      "step": 25700
    },
    {
      "epoch": 1.5232022670917464,
      "grad_norm": 1.530447006225586,
      "learning_rate": 4.767977329082537e-06,
      "loss": 0.5179,
      "step": 25800
    },
    {
      "epoch": 1.5291061518479159,
      "grad_norm": 1.5855445861816406,
      "learning_rate": 4.7089384815208415e-06,
      "loss": 0.5218,
      "step": 25900
    },
    {
      "epoch": 1.5350100366040855,
      "grad_norm": 1.5422815084457397,
      "learning_rate": 4.649899633959145e-06,
      "loss": 0.5302,
      "step": 26000
    },
    {
      "epoch": 1.540913921360255,
      "grad_norm": 1.637337327003479,
      "learning_rate": 4.59086078639745e-06,
      "loss": 0.5198,
      "step": 26100
    },
    {
      "epoch": 1.5468178061164246,
      "grad_norm": 1.5685449838638306,
      "learning_rate": 4.531821938835754e-06,
      "loss": 0.5124,
      "step": 26200
    },
    {
      "epoch": 1.5527216908725943,
      "grad_norm": 1.729411005973816,
      "learning_rate": 4.472783091274059e-06,
      "loss": 0.5217,
      "step": 26300
    },
    {
      "epoch": 1.5586255756287637,
      "grad_norm": 1.5362602472305298,
      "learning_rate": 4.413744243712363e-06,
      "loss": 0.5188,
      "step": 26400
    },
    {
      "epoch": 1.5645294603849331,
      "grad_norm": 1.6397368907928467,
      "learning_rate": 4.354705396150667e-06,
      "loss": 0.5246,
      "step": 26500
    },
    {
      "epoch": 1.5704333451411028,
      "grad_norm": 1.7109838724136353,
      "learning_rate": 4.295666548588972e-06,
      "loss": 0.5265,
      "step": 26600
    },
    {
      "epoch": 1.5763372298972724,
      "grad_norm": 1.6085530519485474,
      "learning_rate": 4.236627701027276e-06,
      "loss": 0.5248,
      "step": 26700
    },
    {
      "epoch": 1.582241114653442,
      "grad_norm": 1.518250823020935,
      "learning_rate": 4.177588853465581e-06,
      "loss": 0.5137,
      "step": 26800
    },
    {
      "epoch": 1.5881449994096115,
      "grad_norm": 1.5456023216247559,
      "learning_rate": 4.1185500059038854e-06,
      "loss": 0.5236,
      "step": 26900
    },
    {
      "epoch": 1.594048884165781,
      "grad_norm": 1.591331958770752,
      "learning_rate": 4.059511158342189e-06,
      "loss": 0.5255,
      "step": 27000
    },
    {
      "epoch": 1.5999527689219506,
      "grad_norm": 1.5715010166168213,
      "learning_rate": 4.000472310780494e-06,
      "loss": 0.5197,
      "step": 27100
    },
    {
      "epoch": 1.6058566536781202,
      "grad_norm": 1.477949857711792,
      "learning_rate": 3.941433463218799e-06,
      "loss": 0.5205,
      "step": 27200
    },
    {
      "epoch": 1.61176053843429,
      "grad_norm": 1.4612443447113037,
      "learning_rate": 3.882394615657103e-06,
      "loss": 0.5239,
      "step": 27300
    },
    {
      "epoch": 1.6176644231904593,
      "grad_norm": 1.4664452075958252,
      "learning_rate": 3.8233557680954066e-06,
      "loss": 0.5214,
      "step": 27400
    },
    {
      "epoch": 1.6235683079466288,
      "grad_norm": 1.5884679555892944,
      "learning_rate": 3.7643169205337117e-06,
      "loss": 0.5174,
      "step": 27500
    },
    {
      "epoch": 1.6294721927027984,
      "grad_norm": 1.653533697128296,
      "learning_rate": 3.705278072972016e-06,
      "loss": 0.5325,
      "step": 27600
    },
    {
      "epoch": 1.635376077458968,
      "grad_norm": 1.6051775217056274,
      "learning_rate": 3.6462392254103203e-06,
      "loss": 0.5341,
      "step": 27700
    },
    {
      "epoch": 1.6412799622151377,
      "grad_norm": 1.4488410949707031,
      "learning_rate": 3.5872003778486247e-06,
      "loss": 0.5247,
      "step": 27800
    },
    {
      "epoch": 1.6471838469713072,
      "grad_norm": 1.6830917596817017,
      "learning_rate": 3.5281615302869294e-06,
      "loss": 0.52,
      "step": 27900
    },
    {
      "epoch": 1.6530877317274766,
      "grad_norm": 1.5273083448410034,
      "learning_rate": 3.4691226827252333e-06,
      "loss": 0.5198,
      "step": 28000
    },
    {
      "epoch": 1.6589916164836462,
      "grad_norm": 1.4999886751174927,
      "learning_rate": 3.410083835163538e-06,
      "loss": 0.5156,
      "step": 28100
    },
    {
      "epoch": 1.664895501239816,
      "grad_norm": 1.4951270818710327,
      "learning_rate": 3.3510449876018423e-06,
      "loss": 0.5291,
      "step": 28200
    },
    {
      "epoch": 1.6707993859959853,
      "grad_norm": 1.7922903299331665,
      "learning_rate": 3.2920061400401466e-06,
      "loss": 0.5229,
      "step": 28300
    },
    {
      "epoch": 1.676703270752155,
      "grad_norm": 1.5956944227218628,
      "learning_rate": 3.232967292478451e-06,
      "loss": 0.5249,
      "step": 28400
    },
    {
      "epoch": 1.6826071555083244,
      "grad_norm": 1.5333561897277832,
      "learning_rate": 3.1739284449167557e-06,
      "loss": 0.523,
      "step": 28500
    },
    {
      "epoch": 1.688511040264494,
      "grad_norm": 1.7396243810653687,
      "learning_rate": 3.1148895973550596e-06,
      "loss": 0.5172,
      "step": 28600
    },
    {
      "epoch": 1.6944149250206637,
      "grad_norm": 1.7129156589508057,
      "learning_rate": 3.0558507497933643e-06,
      "loss": 0.5266,
      "step": 28700
    },
    {
      "epoch": 1.7003188097768331,
      "grad_norm": 1.5561814308166504,
      "learning_rate": 2.996811902231669e-06,
      "loss": 0.5178,
      "step": 28800
    },
    {
      "epoch": 1.7062226945330026,
      "grad_norm": 1.428615927696228,
      "learning_rate": 2.937773054669973e-06,
      "loss": 0.5168,
      "step": 28900
    },
    {
      "epoch": 1.7121265792891722,
      "grad_norm": 1.6071722507476807,
      "learning_rate": 2.8787342071082772e-06,
      "loss": 0.5239,
      "step": 29000
    },
    {
      "epoch": 1.7180304640453419,
      "grad_norm": 1.4032325744628906,
      "learning_rate": 2.819695359546582e-06,
      "loss": 0.5177,
      "step": 29100
    },
    {
      "epoch": 1.7239343488015115,
      "grad_norm": 1.4735876321792603,
      "learning_rate": 2.760656511984886e-06,
      "loss": 0.5204,
      "step": 29200
    },
    {
      "epoch": 1.729838233557681,
      "grad_norm": 1.4964526891708374,
      "learning_rate": 2.7016176644231906e-06,
      "loss": 0.52,
      "step": 29300
    },
    {
      "epoch": 1.7357421183138504,
      "grad_norm": 1.4268622398376465,
      "learning_rate": 2.6425788168614953e-06,
      "loss": 0.5167,
      "step": 29400
    },
    {
      "epoch": 1.74164600307002,
      "grad_norm": 1.7437692880630493,
      "learning_rate": 2.5835399692997992e-06,
      "loss": 0.5187,
      "step": 29500
    },
    {
      "epoch": 1.7475498878261897,
      "grad_norm": 1.7042065858840942,
      "learning_rate": 2.524501121738104e-06,
      "loss": 0.524,
      "step": 29600
    },
    {
      "epoch": 1.7534537725823593,
      "grad_norm": 1.6711206436157227,
      "learning_rate": 2.4654622741764083e-06,
      "loss": 0.5166,
      "step": 29700
    },
    {
      "epoch": 1.7593576573385288,
      "grad_norm": 1.6746268272399902,
      "learning_rate": 2.4064234266147126e-06,
      "loss": 0.5198,
      "step": 29800
    },
    {
      "epoch": 1.7652615420946982,
      "grad_norm": 1.4429242610931396,
      "learning_rate": 2.347384579053017e-06,
      "loss": 0.5234,
      "step": 29900
    },
    {
      "epoch": 1.7711654268508679,
      "grad_norm": 1.5659568309783936,
      "learning_rate": 2.2883457314913216e-06,
      "loss": 0.5231,
      "step": 30000
    },
    {
      "epoch": 1.7770693116070375,
      "grad_norm": 1.4626662731170654,
      "learning_rate": 2.229306883929626e-06,
      "loss": 0.5125,
      "step": 30100
    },
    {
      "epoch": 1.782973196363207,
      "grad_norm": 1.5311408042907715,
      "learning_rate": 2.1702680363679302e-06,
      "loss": 0.5259,
      "step": 30200
    },
    {
      "epoch": 1.7888770811193766,
      "grad_norm": 1.5521188974380493,
      "learning_rate": 2.1112291888062346e-06,
      "loss": 0.5251,
      "step": 30300
    },
    {
      "epoch": 1.794780965875546,
      "grad_norm": 1.5257339477539062,
      "learning_rate": 2.052190341244539e-06,
      "loss": 0.5207,
      "step": 30400
    },
    {
      "epoch": 1.8006848506317157,
      "grad_norm": 1.7757099866867065,
      "learning_rate": 1.9931514936828436e-06,
      "loss": 0.5174,
      "step": 30500
    },
    {
      "epoch": 1.8065887353878853,
      "grad_norm": 1.705264687538147,
      "learning_rate": 1.934112646121148e-06,
      "loss": 0.526,
      "step": 30600
    },
    {
      "epoch": 1.8124926201440548,
      "grad_norm": 1.5598368644714355,
      "learning_rate": 1.8750737985594522e-06,
      "loss": 0.5208,
      "step": 30700
    },
    {
      "epoch": 1.8183965049002242,
      "grad_norm": 1.5905498266220093,
      "learning_rate": 1.8160349509977567e-06,
      "loss": 0.5291,
      "step": 30800
    },
    {
      "epoch": 1.8243003896563939,
      "grad_norm": 1.6562167406082153,
      "learning_rate": 1.756996103436061e-06,
      "loss": 0.5185,
      "step": 30900
    },
    {
      "epoch": 1.8302042744125635,
      "grad_norm": 1.7663439512252808,
      "learning_rate": 1.6979572558743654e-06,
      "loss": 0.5186,
      "step": 31000
    },
    {
      "epoch": 1.8361081591687332,
      "grad_norm": 1.6298123598098755,
      "learning_rate": 1.6389184083126699e-06,
      "loss": 0.5182,
      "step": 31100
    },
    {
      "epoch": 1.8420120439249026,
      "grad_norm": 1.4494365453720093,
      "learning_rate": 1.5798795607509742e-06,
      "loss": 0.5229,
      "step": 31200
    },
    {
      "epoch": 1.847915928681072,
      "grad_norm": 1.4052855968475342,
      "learning_rate": 1.5208407131892785e-06,
      "loss": 0.5298,
      "step": 31300
    },
    {
      "epoch": 1.8538198134372417,
      "grad_norm": 1.5043376684188843,
      "learning_rate": 1.4618018656275832e-06,
      "loss": 0.5206,
      "step": 31400
    },
    {
      "epoch": 1.8597236981934113,
      "grad_norm": 1.710151195526123,
      "learning_rate": 1.4027630180658873e-06,
      "loss": 0.5215,
      "step": 31500
    },
    {
      "epoch": 1.865627582949581,
      "grad_norm": 1.6747795343399048,
      "learning_rate": 1.3437241705041917e-06,
      "loss": 0.5109,
      "step": 31600
    },
    {
      "epoch": 1.8715314677057504,
      "grad_norm": 1.462998628616333,
      "learning_rate": 1.2846853229424964e-06,
      "loss": 0.5289,
      "step": 31700
    },
    {
      "epoch": 1.8774353524619198,
      "grad_norm": 1.6884337663650513,
      "learning_rate": 1.2256464753808007e-06,
      "loss": 0.5238,
      "step": 31800
    },
    {
      "epoch": 1.8833392372180895,
      "grad_norm": 1.5401978492736816,
      "learning_rate": 1.166607627819105e-06,
      "loss": 0.5166,
      "step": 31900
    },
    {
      "epoch": 1.8892431219742591,
      "grad_norm": 1.5211169719696045,
      "learning_rate": 1.1075687802574095e-06,
      "loss": 0.5206,
      "step": 32000
    },
    {
      "epoch": 1.8951470067304286,
      "grad_norm": 1.503414511680603,
      "learning_rate": 1.0485299326957138e-06,
      "loss": 0.5208,
      "step": 32100
    },
    {
      "epoch": 1.9010508914865982,
      "grad_norm": 1.5161786079406738,
      "learning_rate": 9.894910851340182e-07,
      "loss": 0.5126,
      "step": 32200
    },
    {
      "epoch": 1.9069547762427677,
      "grad_norm": 1.5227781534194946,
      "learning_rate": 9.304522375723227e-07,
      "loss": 0.5173,
      "step": 32300
    },
    {
      "epoch": 1.9128586609989373,
      "grad_norm": 1.5515888929367065,
      "learning_rate": 8.714133900106271e-07,
      "loss": 0.5143,
      "step": 32400
    },
    {
      "epoch": 1.918762545755107,
      "grad_norm": 1.7274733781814575,
      "learning_rate": 8.123745424489314e-07,
      "loss": 0.5222,
      "step": 32500
    },
    {
      "epoch": 1.9246664305112764,
      "grad_norm": 1.5937083959579468,
      "learning_rate": 7.533356948872358e-07,
      "loss": 0.5249,
      "step": 32600
    },
    {
      "epoch": 1.9305703152674458,
      "grad_norm": 1.6379116773605347,
      "learning_rate": 6.942968473255402e-07,
      "loss": 0.5171,
      "step": 32700
    },
    {
      "epoch": 1.9364742000236155,
      "grad_norm": 1.5454312562942505,
      "learning_rate": 6.352579997638448e-07,
      "loss": 0.5221,
      "step": 32800
    },
    {
      "epoch": 1.9423780847797851,
      "grad_norm": 1.6756038665771484,
      "learning_rate": 5.762191522021491e-07,
      "loss": 0.5236,
      "step": 32900
    },
    {
      "epoch": 1.9482819695359548,
      "grad_norm": 1.6598598957061768,
      "learning_rate": 5.171803046404535e-07,
      "loss": 0.517,
      "step": 33000
    },
    {
      "epoch": 1.9541858542921242,
      "grad_norm": 1.4477661848068237,
      "learning_rate": 4.5814145707875785e-07,
      "loss": 0.5223,
      "step": 33100
    },
    {
      "epoch": 1.9600897390482936,
      "grad_norm": 1.5338854789733887,
      "learning_rate": 3.9910260951706227e-07,
      "loss": 0.5114,
      "step": 33200
    },
    {
      "epoch": 1.9659936238044633,
      "grad_norm": 1.7712286710739136,
      "learning_rate": 3.4006376195536663e-07,
      "loss": 0.5073,
      "step": 33300
    },
    {
      "epoch": 1.971897508560633,
      "grad_norm": 1.5134707689285278,
      "learning_rate": 2.8102491439367105e-07,
      "loss": 0.5108,
      "step": 33400
    },
    {
      "epoch": 1.9778013933168026,
      "grad_norm": 1.9001610279083252,
      "learning_rate": 2.2198606683197544e-07,
      "loss": 0.5199,
      "step": 33500
    },
    {
      "epoch": 1.983705278072972,
      "grad_norm": 1.7294974327087402,
      "learning_rate": 1.6294721927027986e-07,
      "loss": 0.5164,
      "step": 33600
    },
    {
      "epoch": 1.9896091628291415,
      "grad_norm": 1.7915071249008179,
      "learning_rate": 1.0390837170858425e-07,
      "loss": 0.5251,
      "step": 33700
    },
    {
      "epoch": 1.9955130475853111,
      "grad_norm": 1.6760834455490112,
      "learning_rate": 4.486952414688866e-08,
      "loss": 0.5161,
      "step": 33800
    }
  ],
  "logging_steps": 100,
  "max_steps": 33876,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 2500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 384,
  "trial_name": null,
  "trial_params": null
}
